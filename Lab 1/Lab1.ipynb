{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "Authors: Jeffrey Taylor, Austin Hayden, Eric Bernard, Riley Galante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "This data can be useful in identifying trends in popular YouTube videos with the goal of predicting whether a particular video will be popular or not. \n",
    "Coming from the dataset’s description, “YouTube (the world-famous video sharing website) maintains a list of the top trending videos on the platform. According to Variety magazine, “To determine the year’s top-trending videos, YouTube uses a combination of factors including measuring users interactions (number of views, shares, comments and likes). Note that they’re not the most-viewed videos overall for the calendar year”. Top performers on the YouTube trending list are music videos (such as the famously virile “Gangam Style”), celebrity and/or reality TV performances, and the random dude-with-a-camera viral videos that YouTube is well-known for.”\n",
    "The important thing to note here is that there are many different factors used to determine the popularity of a video, and it is not solely determined by the number of views. By analyzing the dataset and looking at trends, we can determine what factors affect how popular a YouTube video will be. Once we know which factors to look at, we will be able to predict whether future videos will end up trending or not. \n",
    "The data presented in this dataset was collected using the YouTube API and includes several months of data on daily trending YouTube videos. Data is included and separated by region with up to 200 listed trending videos per day although we are only interested in and will be looking at the data pertaining to the US. Some features of the data include, video title, channel title, publish time, tags, views, likes, dislikes, description, and comment count. The data also includes a category_id feature that has a corresponding file reveling the category each ID is associated with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third-Party Interest\n",
    "The end goal of analyzing this dataset is to determine whether a video that is uploaded to YouTube will end up trending or not. Having a prediction algorithm such as this one would be of interest to many advertising agencies or departments. According to YouTube’s Advertising service (https://www.youtube.com/intl/en_us/ads/), viewers are 2x more likely to buy something they saw on YouTube and 4x more likely to use YouTube over any other platform to find information about a brand product or service. Also, over 70% of viewers say that YouTube makes them more aware of new brands. With that being said, YouTube is a great platform to use to get people interested and more aware of your product or service. However, an ad campaign can achieve much greater success reaching more people by possessing knowledge of a video’s trend ability. Advertisers will want to associate their advertisement with videos that are predicted to trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure of Success\n",
    "Obviously, the most desirable rate of success for our prediction algorithm would be 100%. However, we believe this algorithm would still be of use to advertisers even with a lower rate of success. We also want our rate of success to be greater than 50% because if we have a success rate of 50% or lower, our prediction algorithm would be no better at predicting a video to be popular or not than flipping a coin would. We think that if we can achieve a success rate of 80% or greater, advertisers would find this algorithm to be very useful. \n",
    "Furthermore, we want to limit the number of false positives to be as close to zero as possible. If our algorithm produces a lot of false positives, advertisers will begin to lose money on failed advertising campaigns. Also, we want false negatives to be as minimal as possible but are more acceptable than a false positive because no one will waste any money or resources on the video it will only be a missed opportunity. \n",
    "\n",
    "Dataset source: https://www.kaggle.com/datasnaek/youtube-new?select=USvideos.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load YouTube Dataset and prepare it for visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "# basically following the example\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/jenyintaylor/MLiP_Group/master/Lab%201/data/USvideos.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)\n",
    "print(\"\\n{:+^60s}\\n\".format(\"\"))\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "Most of the automatically assigned data types by Pandas make a large amount of sense. You have any of the text-based informational data points such as dates, titles, and categories. These pieces of data can be used for determining other information about the videos other than popularity. There are also some information points that are boolean terms to tell you other information such as comments and ratings being disabled, as well as a datapoint telling you if the video is actually able to be accessed anymore. You finally have the information such as views, likes, dislikes, and comment count that are all purely numerical and heavily associated with the popularity of the video by what is known of Youtube's popularity algorithm. The most confusing data type in the data set is category_id, as a number (specifically int) due to the fact that it is hard for a human being to see these numbers and instinctively know what number equates to a certain category. Thankfully the creators of the dataset also provided a json file that will allow you to map from the integer form of the id to the string of it for people to use later on in analysis.\n",
    "## Questions to consider (from an advertiser's perspective)...\n",
    "    What is the general public opinion of trending videos? (likes vs dislikes)\n",
    "    Average number of comments?\n",
    "    How many trending videos end up getting deleted?\n",
    "    How many \n",
    "    \n",
    "    Which category of video trends the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate IDs\n",
    "\n",
    "dup_list = df.duplicated(subset=['video_id'])\n",
    "d = dup_list.tolist().count(True)\n",
    "e = dup_list.tolist().count(False)\n",
    "\n",
    "print('Checking for duplicate IDs suggests a strong likelihood of a multi-day trend.')\n",
    "print(d)\n",
    "print(e)\n",
    "print(100-(6351/40949)*100, \"%\")\n",
    "# This value is the percentage of youtube videos that trend for multiple days \n",
    "\n",
    "\n",
    "# Percentage of videos with more likes than dislikes\n",
    "\n",
    "sum(df.likes>=df.dislikes)/len(df)*100\n",
    "# with this, we can focus on engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by categories\n",
    "\n",
    "df_g = df.groupby(by='category_id')\n",
    "\n",
    "for x,y in df_g:\n",
    "    print('In 2018, there were',len(y),'trending',x,'videos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
