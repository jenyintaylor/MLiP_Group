{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5\n",
    "\n",
    "### Authors:\n",
    "- Riley Galante\n",
    "- Jeffrey Taylor\n",
    "- Austin Hayden\n",
    "- Eric Bernard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alcohol_reference           int64\n",
      "animated_blood              int64\n",
      "blood                       int64\n",
      "blood_and_gore              int64\n",
      "cartoon_violence            int64\n",
      "crude_humor                 int64\n",
      "drug_reference              int64\n",
      "fantasy_violence            int64\n",
      "intense_violence            int64\n",
      "language                    int64\n",
      "lyrics                      int64\n",
      "mature_humor                int64\n",
      "mild_blood                  int64\n",
      "mild_cartoon_violence       int64\n",
      "mild_fantasy_violence       int64\n",
      "mild_language               int64\n",
      "mild_lyrics                 int64\n",
      "mild_suggestive_themes      int64\n",
      "mild_violence               int64\n",
      "no_descriptors              int64\n",
      "nudity                      int64\n",
      "partial_nudity              int64\n",
      "sexual_content              int64\n",
      "sexual_themes               int64\n",
      "simulated_gambling          int64\n",
      "strong_janguage             int64\n",
      "strong_sexual_content       int64\n",
      "suggestive_themes           int64\n",
      "use_of_alcohol              int64\n",
      "use_of_drugs_and_alcohol    int64\n",
      "violence                    int64\n",
      "dtype: object\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1895 entries, 0 to 1894\n",
      "Data columns (total 31 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   alcohol_reference         1895 non-null   int64\n",
      " 1   animated_blood            1895 non-null   int64\n",
      " 2   blood                     1895 non-null   int64\n",
      " 3   blood_and_gore            1895 non-null   int64\n",
      " 4   cartoon_violence          1895 non-null   int64\n",
      " 5   crude_humor               1895 non-null   int64\n",
      " 6   drug_reference            1895 non-null   int64\n",
      " 7   fantasy_violence          1895 non-null   int64\n",
      " 8   intense_violence          1895 non-null   int64\n",
      " 9   language                  1895 non-null   int64\n",
      " 10  lyrics                    1895 non-null   int64\n",
      " 11  mature_humor              1895 non-null   int64\n",
      " 12  mild_blood                1895 non-null   int64\n",
      " 13  mild_cartoon_violence     1895 non-null   int64\n",
      " 14  mild_fantasy_violence     1895 non-null   int64\n",
      " 15  mild_language             1895 non-null   int64\n",
      " 16  mild_lyrics               1895 non-null   int64\n",
      " 17  mild_suggestive_themes    1895 non-null   int64\n",
      " 18  mild_violence             1895 non-null   int64\n",
      " 19  no_descriptors            1895 non-null   int64\n",
      " 20  nudity                    1895 non-null   int64\n",
      " 21  partial_nudity            1895 non-null   int64\n",
      " 22  sexual_content            1895 non-null   int64\n",
      " 23  sexual_themes             1895 non-null   int64\n",
      " 24  simulated_gambling        1895 non-null   int64\n",
      " 25  strong_janguage           1895 non-null   int64\n",
      " 26  strong_sexual_content     1895 non-null   int64\n",
      " 27  suggestive_themes         1895 non-null   int64\n",
      " 28  use_of_alcohol            1895 non-null   int64\n",
      " 29  use_of_drugs_and_alcohol  1895 non-null   int64\n",
      " 30  violence                  1895 non-null   int64\n",
      "dtypes: int64(31)\n",
      "memory usage: 459.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics as mt \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('Video_games_esrb_rating.csv')\n",
    "\n",
    "# map the esrb string values to integers for our target\n",
    "rating = []\n",
    "\n",
    "for i in df['esrb_rating']:\n",
    "    if(i == 'E'):\n",
    "        rating.append(0)\n",
    "    elif(i == 'ET'):\n",
    "        rating.append(1)\n",
    "    elif(i == 'T'):\n",
    "        rating.append(2)\n",
    "    else:\n",
    "        rating.append(3)\n",
    "        \n",
    "del df['title'] #get rid of unnecessary data\n",
    "del df['console']\n",
    "del df['esrb_rating'] #get rid of original column since its been mapped now\n",
    "\n",
    "print(df.dtypes)\n",
    "print(\"\\n{:+^60s}\\n\".format(\"\"))\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Dataset Description\n",
    "For this dataset, the columns are descriptors that go into the esrb rating for a video game. All those colums are binary data, where 1 represents a video game that has that particular attribute and 0 means it does not. Because the esrb rating was in string format, we encoded it. This is seen in the rating array created, that will be changed into a numpy array and transposed into a column so that it can be interpreted as the target data by the classifier. The values encoded were 0, 1, 2, and 3, representing E for everyone, E 10+, T for Teen, and M for Mature respectively. Additionally, we removed unnecessary information from the dataset that would not help our prediction, like the titles and console of the video games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 31)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                320       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 381\n",
      "Trainable params: 381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "y = np.array(rating).T\n",
    "\n",
    "#remaining columns in dataset are used for X\n",
    "X = df.to_numpy()\n",
    "\n",
    "#set up shuffle split using example\n",
    "num_cv_iterations = 200\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n_splits = num_cv_iterations, test_size = 0.2)\n",
    "for train_index, test_index in cv_object.split(X,y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "input_tensor = Input(shape=(num_features,))\n",
    "x = Dense(units=10, activation='relu')(input_tensor)\n",
    "x = Dense(units=5, activation='tanh')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=input_tensor, outputs=predictions)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/31 [..............................] - ETA: 0s - loss: 2.0529 - accuracy: 0.1600WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "31/31 [==============================] - 0s 742us/step - loss: 1.9352 - accuracy: 0.2071\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 704us/step - loss: 1.7114 - accuracy: 0.2071\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 708us/step - loss: 1.6011 - accuracy: 0.2071\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 677us/step - loss: 1.5433 - accuracy: 0.2071\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 681us/step - loss: 1.5092 - accuracy: 0.2071\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 710us/step - loss: 1.4880 - accuracy: 0.2071\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 612us/step - loss: 1.4738 - accuracy: 0.2071\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 614us/step - loss: 1.4636 - accuracy: 0.2071\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 612us/step - loss: 1.4557 - accuracy: 0.2071\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 644us/step - loss: 1.4496 - accuracy: 0.2071\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 613us/step - loss: 1.4448 - accuracy: 0.2071\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 645us/step - loss: 1.4409 - accuracy: 0.2071\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 614us/step - loss: 1.4375 - accuracy: 0.2071\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 742us/step - loss: 1.4348 - accuracy: 0.2071\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4325 - accuracy: 0.2071\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 626us/step - loss: 1.4304 - accuracy: 0.2071\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 741us/step - loss: 1.4287 - accuracy: 0.2071\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 613us/step - loss: 1.4272 - accuracy: 0.2071\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4258 - accuracy: 0.2071\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 645us/step - loss: 1.4246 - accuracy: 0.2071\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 613us/step - loss: 1.4235 - accuracy: 0.2071\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4225 - accuracy: 0.2071\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4217 - accuracy: 0.2071\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 613us/step - loss: 1.4208 - accuracy: 0.2071\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 606us/step - loss: 1.4201 - accuracy: 0.2071\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 613us/step - loss: 1.4194 - accuracy: 0.2071\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 645us/step - loss: 1.4188 - accuracy: 0.2071\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 610us/step - loss: 1.4182 - accuracy: 0.2071\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 617us/step - loss: 1.4177 - accuracy: 0.2071\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.4793 - accuracy: 0.20 - 0s 644us/step - loss: 1.4172 - accuracy: 0.2071\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 580us/step - loss: 1.4168 - accuracy: 0.2071\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 655us/step - loss: 1.4164 - accuracy: 0.2071\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 646us/step - loss: 1.4160 - accuracy: 0.2071\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 710us/step - loss: 1.4156 - accuracy: 0.2071\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 710us/step - loss: 1.4152 - accuracy: 0.2071\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 580us/step - loss: 1.4149 - accuracy: 0.2071\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4146 - accuracy: 0.2071\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 516us/step - loss: 1.4143 - accuracy: 0.2071\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4140 - accuracy: 0.2071\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4137 - accuracy: 0.2071\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4135 - accuracy: 0.2071\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 516us/step - loss: 1.4132 - accuracy: 0.2071\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 547us/step - loss: 1.4130 - accuracy: 0.2071\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4128 - accuracy: 0.2071\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4126 - accuracy: 0.2071\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 516us/step - loss: 1.4124 - accuracy: 0.2071\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4122 - accuracy: 0.2071\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4120 - accuracy: 0.2071\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 516us/step - loss: 1.4118 - accuracy: 0.2071\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 549us/step - loss: 1.4117 - accuracy: 0.2071\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4115 - accuracy: 0.2071\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 580us/step - loss: 1.4113 - accuracy: 0.2071\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4112 - accuracy: 0.2071\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4110 - accuracy: 0.2071\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 580us/step - loss: 1.4109 - accuracy: 0.2071\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4108 - accuracy: 0.2071\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 516us/step - loss: 1.4106 - accuracy: 0.2071\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4105 - accuracy: 0.2071\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 516us/step - loss: 1.4104 - accuracy: 0.2071\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 516us/step - loss: 1.4103 - accuracy: 0.2071\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4101 - accuracy: 0.2071\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4100 - accuracy: 0.2071\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 613us/step - loss: 1.4099 - accuracy: 0.2071\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4098 - accuracy: 0.2071\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4097 - accuracy: 0.2071\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 612us/step - loss: 1.4096 - accuracy: 0.2071\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4095 - accuracy: 0.2071\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4094 - accuracy: 0.2071\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 516us/step - loss: 1.4093 - accuracy: 0.2071\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4092 - accuracy: 0.2071\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 579us/step - loss: 1.4092 - accuracy: 0.2071\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4091 - accuracy: 0.2071\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4090 - accuracy: 0.2071\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4089 - accuracy: 0.2071\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 580us/step - loss: 1.4088 - accuracy: 0.2071\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.3010 - accuracy: 0.18 - 0s 612us/step - loss: 1.4088 - accuracy: 0.2071\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4087 - accuracy: 0.2071\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 548us/step - loss: 1.4086 - accuracy: 0.2071\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4085 - accuracy: 0.2071\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 549us/step - loss: 1.4085 - accuracy: 0.2071\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 516us/step - loss: 1.4084 - accuracy: 0.2071\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4083 - accuracy: 0.2071\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4083 - accuracy: 0.2071\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 517us/step - loss: 1.4082 - accuracy: 0.2071\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4081 - accuracy: 0.2071\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 549us/step - loss: 1.4081 - accuracy: 0.2071\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4080 - accuracy: 0.2071\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 484us/step - loss: 1.4079 - accuracy: 0.2071\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 516us/step - loss: 1.4079 - accuracy: 0.2071\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 484us/step - loss: 1.4078 - accuracy: 0.2071\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 484us/step - loss: 1.4078 - accuracy: 0.2071\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 516us/step - loss: 1.4077 - accuracy: 0.2071\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4076 - accuracy: 0.2071\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 581us/step - loss: 1.4076 - accuracy: 0.2071\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4075 - accuracy: 0.2071\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 613us/step - loss: 1.4075 - accuracy: 0.2071\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4074 - accuracy: 0.2071\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.1847 - accuracy: 0.30 - 0s 548us/step - loss: 1.4074 - accuracy: 0.2071\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 517us/step - loss: 1.4073 - accuracy: 0.2071\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 548us/step - loss: 1.4072 - accuracy: 0.2071\n",
      "[[  0  94   0   0]\n",
      " [  0  89   0   0]\n",
      " [  0 118   0   0]\n",
      " [  0  78   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        94\n",
      "           1       0.23      1.00      0.38        89\n",
      "           2       0.00      0.00      0.00       118\n",
      "           3       0.00      0.00      0.00        78\n",
      "\n",
      "    accuracy                           0.23       379\n",
      "   macro avg       0.06      0.25      0.10       379\n",
      "weighted avg       0.06      0.23      0.09       379\n",
      "\n",
      "Wall time: 2.48 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\infin\\.conda\\envs\\mlenv2020\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=50, verbose=1)\n",
    "from sklearn import metrics as mt\n",
    "yhat_proba = model.predict(X_test)\n",
    "yhat = np.round(yhat_proba)\n",
    "print(mt.confusion_matrix(y_test,yhat))\n",
    "print(mt.classification_report(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "categorical (InputLayer)        [(None, 31)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2 (TensorFlo [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_1 (TensorF [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_2 (TensorF [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_3 (TensorF [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_4 (TensorF [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_5 (TensorF [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_6 (TensorF [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_7 (TensorF [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_8 (TensorF [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_9 (TensorF [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_10 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_11 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_12 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_13 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_14 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_15 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_16 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_17 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_18 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_19 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_20 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_21 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_22 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_23 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_24 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_25 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_26 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_27 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_28 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_29 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherV2_30 (Tensor [(None,)]            0           categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1)            2           tf_op_layer_GatherV2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1)            2           tf_op_layer_GatherV2_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1)            2           tf_op_layer_GatherV2_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1)            2           tf_op_layer_GatherV2_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1)            2           tf_op_layer_GatherV2_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1)            2           tf_op_layer_GatherV2_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1)            2           tf_op_layer_GatherV2_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1)            2           tf_op_layer_GatherV2_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1)            2           tf_op_layer_GatherV2_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1)            2           tf_op_layer_GatherV2_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_27[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_28[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_30 (Embedding)        (None, 1)            2           tf_op_layer_GatherV2_30[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concat_1 (Concatenate)          (None, 31)           0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "                                                                 embedding_4[0][0]                \n",
      "                                                                 embedding_5[0][0]                \n",
      "                                                                 embedding_6[0][0]                \n",
      "                                                                 embedding_7[0][0]                \n",
      "                                                                 embedding_8[0][0]                \n",
      "                                                                 embedding_9[0][0]                \n",
      "                                                                 embedding_10[0][0]               \n",
      "                                                                 embedding_11[0][0]               \n",
      "                                                                 embedding_12[0][0]               \n",
      "                                                                 embedding_13[0][0]               \n",
      "                                                                 embedding_14[0][0]               \n",
      "                                                                 embedding_15[0][0]               \n",
      "                                                                 embedding_16[0][0]               \n",
      "                                                                 embedding_17[0][0]               \n",
      "                                                                 embedding_18[0][0]               \n",
      "                                                                 embedding_19[0][0]               \n",
      "                                                                 embedding_20[0][0]               \n",
      "                                                                 embedding_21[0][0]               \n",
      "                                                                 embedding_22[0][0]               \n",
      "                                                                 embedding_23[0][0]               \n",
      "                                                                 embedding_24[0][0]               \n",
      "                                                                 embedding_25[0][0]               \n",
      "                                                                 embedding_26[0][0]               \n",
      "                                                                 embedding_27[0][0]               \n",
      "                                                                 embedding_28[0][0]               \n",
      "                                                                 embedding_29[0][0]               \n",
      "                                                                 embedding_30[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "combined (Dense)                (None, 1)            32          concat_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 94\n",
      "Trainable params: 94\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_branches = []\n",
    "all_branch_outputs = []\n",
    "\n",
    "input_branch = Input(shape =( X_train.shape[1],),\n",
    "                    dtype='int64',\n",
    "                    name='categorical')\n",
    "\n",
    "\n",
    "for y in range(X_train.shape[1]):\n",
    "    N = max(X_train[y].max(),X_test[y].max())+1\n",
    "    x = tf.gather(input_branch, y, axis = 1)\n",
    "    \n",
    "    x = Embedding(input_dim=N,\n",
    "                 output_dim=int(np.sqrt(N)),\n",
    "                 input_length = 1)(x)\n",
    "    \n",
    "    all_branch_outputs.append(x)\n",
    "    \n",
    "final_branch = concatenate(all_branch_outputs, name='concat_1')\n",
    "final_branch = Dense(units = 1,\n",
    "                    activation='sigmoid',\n",
    "                    name='combined')(final_branch)\n",
    "model = Model(inputs=input_branch, outputs=final_branch)\n",
    "\n",
    "model.compile(optimizer='sgd',loss='mean_squared_error',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 2.1095 - accuracy: 0.2071\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 999us/step - loss: 1.9363 - accuracy: 0.2071\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 867us/step - loss: 1.8099 - accuracy: 0.2071\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.7188 - accuracy: 0.2071\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.6539 - accuracy: 0.2071\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 840us/step - loss: 1.6069 - accuracy: 0.2071\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 802us/step - loss: 1.5723 - accuracy: 0.2071\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 840us/step - loss: 1.5462 - accuracy: 0.2071\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 840us/step - loss: 1.5259 - accuracy: 0.2071\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 936us/step - loss: 1.5102 - accuracy: 0.2071\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4974 - accuracy: 0.2071\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4870 - accuracy: 0.2071\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4784 - accuracy: 0.2071\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.3386 - accuracy: 0.16 - 0s 935us/step - loss: 1.4713 - accuracy: 0.2071\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4652 - accuracy: 0.2071\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4600 - accuracy: 0.2071\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4555 - accuracy: 0.2071\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.4147 - accuracy: 0.12 - 0s 840us/step - loss: 1.4516 - accuracy: 0.2071\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4483 - accuracy: 0.2071\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4453 - accuracy: 0.2071\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 872us/step - loss: 1.4426 - accuracy: 0.2071\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4402 - accuracy: 0.2071\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4380 - accuracy: 0.2071\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4361 - accuracy: 0.2071\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4344 - accuracy: 0.2071\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4328 - accuracy: 0.2071\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4314 - accuracy: 0.2071\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4301 - accuracy: 0.2071\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 872us/step - loss: 1.4288 - accuracy: 0.2071\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4277 - accuracy: 0.2071\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.3596 - accuracy: 0.26 - 0s 838us/step - loss: 1.4267 - accuracy: 0.2071\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4257 - accuracy: 0.2071\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4249 - accuracy: 0.2071\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4240 - accuracy: 0.2071\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 808us/step - loss: 1.4233 - accuracy: 0.2071\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4226 - accuracy: 0.2071\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4219 - accuracy: 0.2071\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4213 - accuracy: 0.2071\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 742us/step - loss: 1.4207 - accuracy: 0.2071\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4201 - accuracy: 0.2071\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4196 - accuracy: 0.2071\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4191 - accuracy: 0.2071\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4187 - accuracy: 0.2071\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4182 - accuracy: 0.2071\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4178 - accuracy: 0.2071\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 775us/step - loss: 1.4174 - accuracy: 0.2071\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4170 - accuracy: 0.2071\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4167 - accuracy: 0.2071\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4164 - accuracy: 0.2071\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4160 - accuracy: 0.2071\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4157 - accuracy: 0.2071\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4154 - accuracy: 0.2071\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4152 - accuracy: 0.2071\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 742us/step - loss: 1.4149 - accuracy: 0.2071\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4146 - accuracy: 0.2071\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4144 - accuracy: 0.2071\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4142 - accuracy: 0.2071\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 775us/step - loss: 1.4139 - accuracy: 0.2071\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4137 - accuracy: 0.2071\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4135 - accuracy: 0.2071\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 775us/step - loss: 1.4133 - accuracy: 0.2071\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4131 - accuracy: 0.2071\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4129 - accuracy: 0.2071\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 808us/step - loss: 1.4128 - accuracy: 0.2071\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4126 - accuracy: 0.2071\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4124 - accuracy: 0.2071\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4123 - accuracy: 0.2071\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4121 - accuracy: 0.2071\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4120 - accuracy: 0.2071\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4118 - accuracy: 0.2071\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4117 - accuracy: 0.2071\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4116 - accuracy: 0.2071\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 775us/step - loss: 1.4114 - accuracy: 0.2071\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 808us/step - loss: 1.4113 - accuracy: 0.2071\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4112 - accuracy: 0.2071\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4111 - accuracy: 0.2071\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4110 - accuracy: 0.2071\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4108 - accuracy: 0.2071\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4107 - accuracy: 0.2071\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 829us/step - loss: 1.4106 - accuracy: 0.2071\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4105 - accuracy: 0.2071\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4104 - accuracy: 0.2071\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4103 - accuracy: 0.2071\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4102 - accuracy: 0.2071\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4102 - accuracy: 0.2071\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4101 - accuracy: 0.2071\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4100 - accuracy: 0.2071\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4099 - accuracy: 0.2071\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4098 - accuracy: 0.2071\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4097 - accuracy: 0.2071\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4097 - accuracy: 0.2071\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4096 - accuracy: 0.2071\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4095 - accuracy: 0.2071\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 775us/step - loss: 1.4094 - accuracy: 0.2071\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4094 - accuracy: 0.2071\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4093 - accuracy: 0.2071\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4092 - accuracy: 0.2071\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4092 - accuracy: 0.2071\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4091 - accuracy: 0.2071\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.1846 - accuracy: 0.30 - 0s 807us/step - loss: 1.4091 - accuracy: 0.2071\n",
      "[[  0  94   0   0]\n",
      " [  0  89   0   0]\n",
      " [  0 118   0   0]\n",
      " [  0  78   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        94\n",
      "           1       0.23      1.00      0.38        89\n",
      "           2       0.00      0.00      0.00       118\n",
      "           3       0.00      0.00      0.00        78\n",
      "\n",
      "    accuracy                           0.23       379\n",
      "   macro avg       0.06      0.25      0.10       379\n",
      "weighted avg       0.06      0.23      0.09       379\n",
      "\n",
      "Wall time: 4.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=50, verbose=1)\n",
    "\n",
    "from sklearn import metrics as mt\n",
    "yhat_proba = model.predict(X_test)\n",
    "yhat = np.round(yhat_proba)\n",
    "print(mt.confusion_matrix(y_test,yhat))\n",
    "print(mt.classification_report(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\infin\\.conda\\envs\\mlenv2020\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c38636436e88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# 1. create crossed labels by join operation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mX_crossed_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mX_crossed_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "cross_columns = [['alcohol_reference','drug_reference'],\n",
    "                 ['animated_blood', 'blood', 'blood_and_gore'],\n",
    "                 ['cartoon_violence','fantasy_violence','intense_violence'],\n",
    "                ]\n",
    "\n",
    "# cross each set of columns in the list above\n",
    "cross_col_df_names = []\n",
    "for cols_list in cross_columns:\n",
    "    # encode as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "    \n",
    "    # 1. create crossed labels by join operation\n",
    "    X_crossed_train = X_train[cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "    X_crossed_test = X_test[cols_list].apply(lambda x: '_'.join(x), axis=1)\n",
    "    \n",
    "    # get a nice name for this new crossed column\n",
    "    cross_col_name = '_'.join(cols_list)\n",
    "    \n",
    "    # 2. encode as integers\n",
    "    enc.fit(np.hstack((X_crossed_train.to_numpy(),  X_crossed_test.to_numpy())))\n",
    "    \n",
    "    # 3. Save into dataframe with new name\n",
    "    X_train[cross_col_name] = enc.transform(X_crossed_train)\n",
    "    X_test[cross_col_name] = enc.transform(X_crossed_test)\n",
    "    \n",
    "    # keep track of the new names of the crossed columns\n",
    "    cross_col_df_names.append(cross_col_name) \n",
    "    \n",
    "cross_col_df_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 0s 936us/step - loss: 1.4090 - accuracy: 0.2071\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4089 - accuracy: 0.2071\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 935us/step - loss: 1.4089 - accuracy: 0.2071\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 935us/step - loss: 1.4088 - accuracy: 0.2071\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4088 - accuracy: 0.2071\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 968us/step - loss: 1.4087 - accuracy: 0.2071\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 936us/step - loss: 1.4087 - accuracy: 0.2071\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 935us/step - loss: 1.4086 - accuracy: 0.2071\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4086 - accuracy: 0.2071\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.6056 - accuracy: 0.18 - 0s 871us/step - loss: 1.4085 - accuracy: 0.2071\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 936us/step - loss: 1.4085 - accuracy: 0.2071\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4084 - accuracy: 0.2071\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4084 - accuracy: 0.2071\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 968us/step - loss: 1.4083 - accuracy: 0.2071\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.3239 - accuracy: 0.16 - 0s 871us/step - loss: 1.4083 - accuracy: 0.2071\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4082 - accuracy: 0.2071\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4082 - accuracy: 0.2071\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4082 - accuracy: 0.2071\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 935us/step - loss: 1.4081 - accuracy: 0.2071\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4081 - accuracy: 0.2071\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4080 - accuracy: 0.2071\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.5246 - accuracy: 0.14 - 0s 903us/step - loss: 1.4080 - accuracy: 0.2071\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4080 - accuracy: 0.2071\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 902us/step - loss: 1.4079 - accuracy: 0.2071\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4079 - accuracy: 0.2071\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 936us/step - loss: 1.4079 - accuracy: 0.2071\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4078 - accuracy: 0.2071\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 935us/step - loss: 1.4078 - accuracy: 0.2071\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4077 - accuracy: 0.2071\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4077 - accuracy: 0.2071\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4077 - accuracy: 0.2071\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4077 - accuracy: 0.2071\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4076 - accuracy: 0.2071\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4076 - accuracy: 0.2071\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4076 - accuracy: 0.2071\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4075 - accuracy: 0.2071\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 936us/step - loss: 1.4075 - accuracy: 0.2071\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4075 - accuracy: 0.2071\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 1000us/step - loss: 1.4074 - accuracy: 0.2071\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4074 - accuracy: 0.2071\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4074 - accuracy: 0.2071\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4074 - accuracy: 0.2071\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4073 - accuracy: 0.2071\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4073 - accuracy: 0.2071\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4073 - accuracy: 0.2071\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4073 - accuracy: 0.2071\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 892us/step - loss: 1.4072 - accuracy: 0.2071\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4072 - accuracy: 0.2071\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4072 - accuracy: 0.2071\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4072 - accuracy: 0.2071\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 1.4621 - accuracy: 0.20 - 0s 806us/step - loss: 1.4071 - accuracy: 0.2071\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4071 - accuracy: 0.2071\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4071 - accuracy: 0.2071\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 968us/step - loss: 1.4071 - accuracy: 0.2071\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4070 - accuracy: 0.2071\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4070 - accuracy: 0.2071\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4070 - accuracy: 0.2071\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4070 - accuracy: 0.2071\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4070 - accuracy: 0.2071\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4069 - accuracy: 0.2071\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4069 - accuracy: 0.2071\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 774us/step - loss: 1.4069 - accuracy: 0.2071\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 807us/step - loss: 1.4069 - accuracy: 0.2071\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 839us/step - loss: 1.4069 - accuracy: 0.2071\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4068 - accuracy: 0.2071\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4068 - accuracy: 0.2071\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 806us/step - loss: 1.4068 - accuracy: 0.2071\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4068 - accuracy: 0.2071\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 968us/step - loss: 1.4068 - accuracy: 0.2071\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 936us/step - loss: 1.4068 - accuracy: 0.2071\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 968us/step - loss: 1.4067 - accuracy: 0.2071\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4067 - accuracy: 0.2071\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4067 - accuracy: 0.2071\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4067 - accuracy: 0.2071\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 968us/step - loss: 1.4067 - accuracy: 0.2071\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 935us/step - loss: 1.4067 - accuracy: 0.2071\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 935us/step - loss: 1.4066 - accuracy: 0.2071\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 935us/step - loss: 1.4066 - accuracy: 0.2071\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4066 - accuracy: 0.2071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 935us/step - loss: 1.4066 - accuracy: 0.2071\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 936us/step - loss: 1.4066 - accuracy: 0.2071\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.4066 - accuracy: 0.2071\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 968us/step - loss: 1.4065 - accuracy: 0.2071\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4065 - accuracy: 0.2071\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4065 - accuracy: 0.2071\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 968us/step - loss: 1.4065 - accuracy: 0.2071\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 935us/step - loss: 1.4065 - accuracy: 0.2071\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4065 - accuracy: 0.2071\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4065 - accuracy: 0.2071\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 968us/step - loss: 1.4064 - accuracy: 0.2071\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 968us/step - loss: 1.4064 - accuracy: 0.2071\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 968us/step - loss: 1.4064 - accuracy: 0.2071\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4064 - accuracy: 0.2071\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4064 - accuracy: 0.2071\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4064 - accuracy: 0.2071\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4064 - accuracy: 0.2071\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 870us/step - loss: 1.4063 - accuracy: 0.2071\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 968us/step - loss: 1.4063 - accuracy: 0.2071\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 871us/step - loss: 1.4063 - accuracy: 0.2071\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 903us/step - loss: 1.4063 - accuracy: 0.2071\n",
      "[[  0  94   0   0]\n",
      " [  0  89   0   0]\n",
      " [  0 118   0   0]\n",
      " [  0  78   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        94\n",
      "           1       0.23      1.00      0.38        89\n",
      "           2       0.00      0.00      0.00       118\n",
      "           3       0.00      0.00      0.00        78\n",
      "\n",
      "    accuracy                           0.23       379\n",
      "   macro avg       0.06      0.25      0.10       379\n",
      "weighted avg       0.06      0.23      0.09       379\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\infin\\.conda\\envs\\mlenv2020\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEGCAYAAAD8EfnwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjSElEQVR4nO3deXxV9Z3/8dcnCzsJIQlbWBIgomGXKIugIi5AXep06lLrdKhT69S17W+qPNpfl5l5dPlN29GZLpYq0k3UqlW07ktFRYGgoGxBZA1r2IKsIcnn98c5QKTZyHbvzXk/H488yD33nHvfySP3zVm/x9wdEZEoSYp1ABGR1qbiE5HIUfGJSOSo+EQkclR8IhI5KbEO0BqysrI8Nzc31jFEpBUtWbJkl7tn1/RcJIovNzeXoqKiWMcQkVZkZhtre06buiISOSo+EYkcFZ+IRI6KT0QiR8UnIpGj4hORyFHxiUjkqPhEJHJUfCISOSo+EYkcFZ+IRI6KT0QiR8UnIpGj4hORyFHxiUjkqPhEJHJUfCISOSo+EYkcFZ+IRI6KT0QiR8UnIpGj4hORyFHxiUjkqPhEJHJUfCISOSo+EYkcFZ+IRI6KT0QiR8UnIpGj4hORyFHxiUjkqPhEJHJiUnxmNtXMis1srZndU8PzN5jZB+HXAjMbWe252Wa208yWt25qEWkrWr34zCwZ+CUwDSgArjezglNmWw9c4O4jgP8AZlV7bg4wtRWiikgbFYs1vnOBte6+zt3LgUeAq6rP4O4L3H1v+PBdoG+15+YDe1orrIi0PbEovhxgc7XHJeG02twEPH+6b2JmN5tZkZkVlZaWnu7iItKGxaL4rIZpXuOMZpMJiu/u030Td5/l7oXuXpidnX26i4tIG5YSg/csAfpVe9wX2HrqTGY2AngAmObuu1spm4hEQCzW+BYD+WaWZ2btgOuAedVnMLP+wJPAje6+JgYZRaQNa/Xic/cK4DbgRWAV8Ji7rzCzW8zslnC27wKZwK/MbKmZFR1f3szmAu8AQ8ysxMxuauUfQUQSnLnXuHutTSksLPSioqL6ZxSRNsPMlrh7YU3P6coNEYkcFZ+IRI6KT0QiR8UnIpGj4hORyFHxiUjkxOLKjbj1g2dWsHLr/ljHEJEaFPRJ43tXDG2W19Ian4hEjtb4qmmu/01EJL5pjU9EIkfFJyKRo+ITkchR8YlI5Kj4RCRyVHwiEjkqPhGJHBWfiESOik9EIkfFJyKRo+ITkchR8YlI5Kj4RCRyVHwiEjkqPhGJHBWfiESOik9EIkfFJyKRo+ITkchR8YlI5Kj4RCRyVHwiEjkqPhGJHBWfiESOik9EIkfFJyKRE5PiM7OpZlZsZmvN7J4anr/BzD4IvxaY2ciGLisiUp9WLz4zSwZ+CUwDCoDrzazglNnWAxe4+wjgP4BZp7GsiEidYrHGdy6w1t3XuXs58AhwVfUZ3H2Bu+8NH74L9G3osiIi9YlF8eUAm6s9Lgmn1eYm4PnTXdbMbjazIjMrKi0tbUJcEWlrYlF8VsM0r3FGs8kExXf36S7r7rPcvdDdC7OzsxsVVETappQYvGcJ0K/a477A1lNnMrMRwAPANHfffTrLiojUJRZrfIuBfDPLM7N2wHXAvOozmFl/4EngRndfczrLiojUp9XX+Ny9wsxuA14EkoHZ7r7CzG4Jn78f+C6QCfzKzAAqws3WGpdt7Z9BRBKbude4i6xNKSws9KKioljHEJFWZGZL3L2wpud05YaIRI6KT0QiR8UnIpGj4hORyFHxiUjkqPhEJHJUfCISOSo+EYkcFZ+IRI6KT0QiR8UnIpGj4hORyInEIAVmVgpsbODsWcCuFozTkpS99SVqbkjc7A3NPcDdaxyFOBLFdzrMrKi2ER3inbK3vkTNDYmbvTlya1NXRCJHxScikaPi+3uzYh2gCZS99SVqbkjc7E3OrX18IhI5WuMTkchR8YlI5Kj4qjGzqWZWbGZrzeyeWOepjZn1M7PXzWyVma0wszvD6d3N7GUz+yj8NyPWWWtjZslm9r6ZPRs+TojsZtbNzB43s9Xh7398ImQ3s6+HfyvLzWyumXWI19xmNtvMdprZ8mrTas1qZjPDz2yxmV3WkPdQ8YXMLBn4JTANKACuN7OC2KaqVQXwTXc/CxgH3BpmvQd41d3zgVfDx/HqTmBVtceJkv0+4AV3PxMYSfAzxHV2M8sB7gAK3X0Ywa1ZryN+c88Bpp4yrcas4d/9dcDQcJlfhZ/lurm7voIDPOOBF6s9ngnMjHWuBmZ/GrgEKAZ6h9N6A8WxzlZL3r7hH+9FwLPhtLjPDqQB6wkPClabHtfZgRxgM9Cd4F7azwKXxnNuIBdYXt/v+NTPKcE9t8fX9/pa4zvp+B/HcSXhtLhmZrnAaGAh0NPdtwGE//aIYbS63At8C6iqNi0Rsg8ESoGHws30B8ysM3Ge3d23AD8FNgHbgDJ3f4k4z32K2rI26nOr4jvJapgW1+f6mFkX4AngLnffH+s8DWFmlwM73X1JrLM0QgpwNvBrdx8NHCR+Ng9rFe4PuwrIA/oAnc3si7FN1Wwa9blV8Z1UAvSr9rgvsDVGWeplZqkEpfcnd38ynLzDzHqHz/cGdsYqXx3OA640sw3AI8BFZvZHEiN7CVDi7gvDx48TFGG8Z78YWO/upe5+DHgSmED8566utqyN+tyq+E5aDOSbWZ6ZtSPYYTovxplqZGYGPAiscvefV3tqHvCl8PsvEez7iyvuPtPd+7p7LsHv+DV3/yKJkX07sNnMhoSTpgArif/sm4BxZtYp/NuZQnBQJt5zV1db1nnAdWbW3szygHxgUb2vFuudmPH0BUwH1gAfA9+OdZ46ck4kWJ3/AFgafk0HMgkOGnwU/ts91lnr+Tku5OTBjYTIDowCisLf/VNARiJkB34ArAaWA38A2sdrbmAuwb7IYwRrdDfVlRX4dviZLQamNeQ9dMmaiESONnVFJHJUfCISOSo+EYmclFgHaA1ZWVmem5sb6xgi0oqWLFmyy2u550aLFZ+ZzQaOn6w6rI75zgHeBa5198fDaVMJrolMBh5w9x+H00cC9wNdgA3ADd6AE3dzc3MpKipq2g8kIgnFzGq9wVhLburO4e8vNP6U8GLinxBcX1d9Wm2DBTwA3OPuw4G/AP/W/LFFpK1rseJz9/nAnnpmu53g6oPqZ4yfC6x193XuXk5wdv9V4XNDgPnh9y8Dn2u+xFBZ5Tz1/haqqnSKj0hbFrODG+FQOVcTbLpWV9dFx8uBK8PvP8+nL1U59fVvNrMiMysqLS1tUKYXlm/nrkeXcvvc9zlcXtmgZUQk8cTyqO69wN3ufmrD1HXR8ZcJxp5bAnQFymt7cXef5e6F7l6YnV3j/s2/M314L2ZOO5Pnlm/julnvsHP/kQYtJyKJJZZHdQuBR4JLB8kCpptZBXVcdOzuqwnGEcPMzgA+05yBzIyvXjCIvKzO3PnIUq74xVvMurGQkf26NefbiEiMxWyNz93z3D3Xg4vVHwe+5u5PUcdgAWbWI/w3CfgOf7+Z3CwuHdqLJ/51AilJSVzzm3d4eumWlngbEYmRFis+M5sLvAMMMbMSM7vJzG4xs1vqWs7dK4DbCI70rgIec/cV4dPXm9kagouttwIPtVT+gj5pzLvtPEb268adjyzlR8+tolIHPUTahEgMUlBYWOiNPY+vvKKK//zrSn7/zkYm5Wfxv9ePplunds2cUESam5ktcffCmp7TJWv1aJeSxL9fNYyffG44C9ft4YpfvMXKrQkx2LGI1ELF10DXntOfR786jvKKKv7h129rv59IAlPxnYbR/TN45vaJjMgJ9vt9f94KjlVW1b+giMQVFd9p6tG1A3/6yli+fF4ecxZs4PpZ77J13+FYxxKR06Dia4TU5CS+e0UB/3P9aFZt289n/udNXl8dz/dpEZHqVHxNcOXIPjxz+0R6pXdkxpzF/PC5VZRXaNNXJN6p+JpoYHYX/vK1CXxxXH9mzV/H53/zDpt2H4p1LBGpg4qvGXRITeY/PzucX99wNutKDzD9f97k8SUlROEcSZFEpOJrRtOG9+b5OydR0CeN//PnZdz28PvsPVjrOAoiEiOnVXxmlmRmaS0Vpi3om9GJuV8Zx7emDuGlldu57N75vF6sAx8i8aTe4jOzh80szcw6E9w1vtjMNPJxHZKTjK9dOJinbj2Pbp1SmfHQYmY++SEHjlbEOpqI0LA1voLwvhafBZ4D+gM3tmSotmJon3Tm3TaRr54/kEcWb2LqvfN55+PdsY4lEnkNKb5UM0slKL6n3f0YJwcGlXp0SE1m5vSz+PNXx5OSZFz/23f5/rwVHCrX2p9IrDSk+H5DcEezzsB8MxsA6Cr901SY253n7zyfGeflMmfBBqbd9ybvrtPan0gsNGpYKjNLCcfNSwhNGZaqJby7bjd3P/EBG3cf4sZxA7h72pl0aR+JWxyLtJomDUtlZneGBzfMzB40s/eAi5o9ZYSMG5jJ83dO4qaJefxx4UYu/fkbOvIr0ooasqn75fDgxqVANjAD+HGLpoqATu1S+L+XF/D4LRPo3D6FGQ8t5q5H3mf3gaOxjibS5jWk+I7f9Ww68JC7L6PmO6FJI4wZkMGzd0zkjin5/PXDbVz88zd48j1d9SHSkhpSfEvM7CWC4nvRzLoCuhK/GbVPSeYbl5zBs7dPIjerM994bBk3PriIDbsOxjqaSJtU78GN8I5mo4B17r7PzDKBHHf/oBXyNYt4O7hRl8oq5+GFG/l/LxRTXlnFbZMHc/MFA2mfkhzraCIJpUkHN9y9iuDett8xs58CExKp9BJNcpJx4/hcXvnmBVx8Vk9+9vIapt/3Jgs+3hXraCJtRkOO6v4YuJPgcrWVwB1m9qOWDhZ1PdM68MsbzuahGedQXlnFF367kNsefo9tZRrtWaSpGrKp+wEwKlzzw8ySgffdfUQr5GsWibSpW5Mjxyq5/42P+fXfPiY5ybj9onxumphHuxQNriNSm+a4vWS3at+nNzmRnJYOqcncdfEZvPz1C5gwKIufvLCaqffO57XVO3T0V6QRGlJ8PwLeN7M5ZvY7YAnww5aNJTXpn9mJB75UyEMzzgHgy3OK+KfZi1iz45MYJxNJLA05uDEXGAc8GX6NB9bXt5yZzTaznWa2vJ75zjGzSjP7x2rTpppZsZmtNbN7qk0fZWbvmtlSMysys3Pry9EWTR7SgxfuOp/vXl7Ass37mHrvfL7z1Ic6+VmkgRp7re4md+9fzzznAweA37v7sFrmSQZeBo4As9398XDaGuASoARYDFzv7ivD8wn/292fN7PpwLfc/cL68ib6Pr667D1Yzr2vrOGPCzfRKTWZWy8azD9PyKVDqk5/kWhrjn18f/ea9c3g7vOBPfXMdjvwBFD9QtVzgbXuvs7dy4FHgKuOvyxwfATodGDr6YRuizI6t+MHVw3jxbsmcW5ed378/Gqm/Cy4+qOqSvv/RGrS2OJr8ifKzHKAq4H7T3kqB9hc7XFJOA3gLuC/zGwz8FNgZh2vf3O4OVxUWlra1Lhxb3CPrjz4z+fw8L+MJaNzKt94bBmf+d+3eL14pw6AiJyi1rGQzOwZai44AzKb4b3vBe5290qzT61A1rQ2eTzHvwJfd/cnzOwa4EHg4ppe3N1nAbMg2NRthrwJYcLgLObdOpFnP9zGT18sZsZDizk3rzt3Tx3CmAHdYx1PJC7Uuo/PzC6oa0F3f6PeFzfLBZ6taR+fma3nZMllAYeAm4EdwPfd/bJwvpnh+/3IzMqAbu7uFrRlmbvXe/OjtryPry7lFVU8ungT9726ll0HjnLhkGy+eckQhvfVGUnS9tW1j6/WNb6GFFtTuHve8e/NbA5BQT5lZilAvpnlAVuA64AvhLNuBS4A/kYwJuBHLZkx0bVLSeLG8bl8bkxffv/ORu5/42Ou+MVbXDa0J9+4ZAhDenWNdUSRmGixYX/NbC5wIZBlZiXA94BUAHc/db/eCe5eYWa3AS8CyQRHe1eET38FuC8sxyMEa4hSj07tUrjlgkHcMLY/s9/awANvruOllfP5zPDe3DElnzN6qgAlWhp1Okuiieqmbm32HSpn1vx1/G7BBg6WV54oQK0BSltS16auii/C9h4s58G31jNnwQYOHK1g+vBe3DY5n4I+ume8JL4mFV8tR3fLgCLgN+5+pFlStiAVX932HQoK8KG3gwK8+Kwe3Dp5MKP7Z8Q6mkijNbX47iO418bccNK1wHagI5Dm7nF/c3EVX8OUHTrG797ZwOy317Pv0DHGD8zkXy8cxKT8LE455Ugk7jW1+Oa7+/k1TTOzFe4+tBmztggV3+k5eLSCuYs28ds317Fj/1GG5aRxywWDmDq0FynJGgpLEkNTL1nLNrMT1+WG32eFD8ubIZ/Emc7tU/iXSQOZ/63J/ORzwzl0tJLbHn6fyT/7G7PfWs+BowlzS2WRGjVkjW86wWVlHxOccJwHfI3gXLqvuPu9LRux6bTG1zSVVc7LK3fwwJvrKNq4l64dUvjC2P7884Rceqd3jHU8kRo1+aiumbUHziQovtWJcECjOhVf83l/014eeGs9z3+4jSQzrhjZh3+ZlMfQProaROJLcxTfBCCXaic8u/vvmytgS1PxNb/New7x0NsbeHTxJg6WVzI2rzszzsvlkoJeJCfpQIjEXlMPbvwBGAQsBSrDye7udzRnyJak4ms5ZYeP8ejiTfxuwUa27DtMTreO/NP4AVx7Tj+6dWoX63gSYU0tvlVAgSfwmc4qvpZXUVnFK6t2MGfBBt5dt4eOqclcfXYOMybkkq9L4iQGGjVIQTXLgV7AtmZNJW1KSnISU4f1Zuqw3qzatp85b2/g8SUlPLxwExMGZfJP43O5+KweOh1G4kJD1vheB0YBi4ATN3Vw9ytbNFkz0hpfbOw5WM7cRZt4eOEmtuw7TM+09lxb2I9rzulH34xOsY4nbVxTN3VrHJevpYetak4qvtiqqKzitdU7mbtoE39bE4yGfeEZ2Xxh7AAmD8nWWqC0CA1SoOKLGyV7D/HY4s08sngzOz85So+u7fl8YV+uKezHgMzOsY4nbUijis/M3nL3iWb2CZ8epMAIjuomzBAeKr74cyxcC3x08Wb+VryTKoexed25prAf04b3olO7FhsqUiJCa3wqvri2vewIT7xXwp+LNrNh9yG6tE/h8hG9+dyYvhQOyNAACdIozXECczLQk0+fwLyp2RK2MBVfYnB3Fm/Yy2NFm3nuw20cKq9kQGYnPjsqh6tH55CbpU1habimHty4nWDY+B1AVTjZ3X1Es6ZsQSq+xHPwaAUvrtjOE++VsODj3bjD2f27cfXoHC4f0YeMzjo5WurW1OJbC4x1990tEa41qPgS27aywzy9dCt/eW8LxTs+ITXZuOCMbK4Y2YdLCnpqf6DUqKnF9zpwibsn7FhEKr62wd1ZuW0/T72/hWeWbWP7/iN0apfMpQU9uXJUHyblZ5OqU2Mk1NTiexAYAvyVT5/A/PPmDNmSVHxtT1WVs2jDHp5eupXnPtxG2eFjdOuUyrRhvbliRG/GDszUYAkR19Ti+15N0939B82QrVWo+Nq28ooq3vyolHnLtvLyyh0cKq8ku2t7pg/rxeUj+zCmfwZJKsHI0eksKr7IOFxeyWurd/LMsq28VryT8ooqeqV1YOqwXkwf3psxAzK0JhgRjT2B+V53v6uWu6zpWl2JeweOVvDKyh389cNtvLGmlPKKKrK7tufSgp5MG9absQO7a59gG9bY4hvj7ksae62umc0GLgd2uvuwOuY7B3gXuNbdHw+nTQXuA5KBB9z9x+H0Rwn2NwJ0A/a5+6i6coCKT4ISfG31Tl5Yvo3XV5dy+Fgl3TqlMuXMnlw2tCfnn5FNh9TkWMeUZhSTTV0zOx84APy+tuILT4x+GTgCzHb3x8Npa4BLgBJgMXC9u688ZdmfAWXu/u/1ZVHxSXWHyyuZ/1EpLyzfzqurdrD/SAUdU5OZlJ/FxQU9mXJmDzK7tI91TGmiJo3HZ2b5wI+AAqDD8enuPrCu5dx9vpnl1vPytwNPAOdUm3YusNbd14Xv/whwFXCi+Cy4huka4KL68oucqmO7ZC4b2ovLhvbiWGUVC9ft4aWV23ll5Q5eWrmDJIMxAzK4pKAnU87qyaDsLrGOLM2sIWd+PkRw5cZ/A5OBGQQDFTSJmeUAVxOUV/XiywE2V3tcAow9ZfFJwA53/6iO178ZuBmgf//+tc0mEZeanMTE/Cwm5mfxgyuHsmLrfl5euYOXV+7gh8+t5ofPrWZgVmemnNWDi8/qyZgBGRpGqw1oSPF1dPdXzczcfSPwfTN7k6AMm+Je4G53rzzlIvSaSvXU7fHrgbl1vbi7zwJmQbCp2/iYEhVmxrCcdIblpPP1S85gy77DvLYqWAucs2ADv31zPWkdUjj/jGwmD+nBBUOyydImcUJqSPEdMbMk4CMzuw3YAvRohvcuBB4JSy8LmG5mFQRreP2qzdcX2Hr8gZmlAP8AjGmGDCK1yunWkRvH53Lj+FwOHK3gzTWlvF68k9eLS3n2g22YwYicdCaf2YPJQ3owPCdd5wsmiIacwHwOsIrgKOp/AGnAf7n7u/W+eLCP79m6juqG880J53s8LLY1wBSCkl0MfMHdV4TzTgVmunuNR5trooMb0pyqqoJL515fvZPXineydPM+3CGjUyoT87OZlJ/FpPws3Ww9xhp9cCM8wnqNu/8bwRHaGafxpnOBC4EsMysh2DROBXD3+2tbzt0rwjXLFwlOZ5l9vPRC11HPZq5IS0pKOrlJfPuUfPYcLGf+mlLmf1TKmx/t4pllwQZKfo8unH9GNuefkc3YvO46XSaO1HUeX0pYQq8BU3R7SZH6uTvFOz4JinDNLhZt2EN5RRXtUpIYm9ediYODAyln9UrTZnELa+wJzO+5+9nh+XL5wJ+Bg8efd/cnWyJsS1DxSawcLq9k4frdvPnRLuavKeWjnQcAyOzcjvGDMpk4OIvxgzLp372TRppuZk29r253YDfBaSdOeM8NIGGKTyRWOrZL5sIhPbhwSHA8cHvZEd5eu4u31u7i7bW7ePaD4HbVfdI7MG5QJuMHZjJhcBY53bR/sCXVtcZXAvyck0VX/b8j17BUIk3j7nxceoB31u3h3Y9388663ew5WA5A/+6dGDewO+MGZjJ2YKaKsBEau8aXDHShYefVichpMjMG9+jK4B5duXHcAKqqnDU7P+Gdj3fzzse7eXHFDh4rKgGgb0ZHxuZlMnZgd8blZdKve0dtGjdBvfv4WjlPi9AanySiqipn9fZPWLh+NwvX7WHh+t3sPXQMgF5pHTgnrzvn5mZwbl4m+T266GDJKRq7xqffokgMJSUZBX3SKOiTxozz8qiqctaWHmDh+j0sWr+HRet3nzh1plunVAoHZDBmQHfGDMhgRN90nT5Th7qKb0qrpRCReiUlGWf07MoZPYNNY3dn055DLFq/h8Ub9lC0YS+vrNoJQGpycK7hmP4ZFOYGhZjdVZfXHacRmEXakD0Hy1mycW/4tYdlJWWUVwR3he3XvSNn98848XVm765teiBWDT2v4pOIOlpRyfItZSzZuJf3Nu7jvU172flJcM+w9ilJDM9JZ1S/bowZkMHZAzLomdahnldMHCo+FZ8IEJxCs2XfYd7btI9lm/exdPM+Ptxycq2wd3oHRvbtxsh+3RjZL53hOel07ZAa49SN09QTmEWkjTAz+mZ0om9GJ64c2QcI7lK3YmvZp8rwhRXbw/lhYFZnRvTtxvCcdEb0TaegT1rC38Q9sdOLSJO1S0lidP8MRvfPODFt78FylpXs48OSMpaVlPH22l385f0tACQZ5PfoyrCcdIbnpDG8bzoFvdPp2C5xjiJrU1dEGmTH/iMs27yP5VvK+HBLGR9u2c+uA8H+wiSDQdldGJaTztA+aQztE6wZpneM3Way9vGp+ESanbuzY//RsATLWL6ljBVby9ix/+iJefp178iwPuknCrGgTxo9urbOARTt4xORZmdm9ErvQK/0DlxS0PPE9NJPjrJiaxkrtu5n5db9LN9axvPLt594PqtLe87q3ZWzeqed+HdQdpdWPbVGxScizSq7a/tPjUgDUHb4GKu27WfF1v2s3rafVdv3M2fBhhNHk9ulJDGkZ1fO7NWVIb26cmavNIb06tpiJ12r+ESkxaV3TGXcwEzGDcw8Ma2isop1uw6ycuv+E6X4evFO/ryk5MQ8mZ3bcWbvrgzpmcbIfulcNSqnWfKo+EQkJlKSk05cgvfZ0ScLbdeBoxRv/4TV2z9h9bb9FO/4hIcXbeS9TWkqPhFpm7K6tCdrcHvOG5x1YlpllbPvUHmzvUfbvVBPRNqM5CQjsxnvYaziE5HIUfGJSORE4gRmMysFNjZw9ixgVwvGaUnK3voSNTckbvaG5h7g7tk1PRGJ4jsdZlZU29ne8U7ZW1+i5obEzd4cubWpKyKRo+ITkchR8f29WbEO0ATK3voSNTckbvYm59Y+PhGJHK3xiUjkqPhEJHJUfNWY2VQzKzaztWZ2T6zz1MbM+pnZ62a2ysxWmNmd4fTuZvaymX0U/ptR32vFipklm9n7ZvZs+DghsptZNzN73MxWh7//8YmQ3cy+Hv6tLDezuWbWIV5zm9lsM9tpZsurTas1q5nNDD+zxWZ2WUPeQ8UXMrNk4JfANKAAuN7MCmKbqlYVwDfd/SxgHHBrmPUe4FV3zwdeDR/HqzuBVdUeJ0r2+4AX3P1MYCTBzxDX2c0sB7gDKHT3YUAycB3xm3sOMPWUaTVmDf/urwOGhsv8Kvws183d9RUc4BkPvFjt8UxgZqxzNTD708AlQDHQO5zWGyiOdbZa8vYN/3gvAp4Np8V9diANWE94ULDa9LjODuQAm4HuBCMyPQtcGs+5gVxgeX2/41M/p8CLwPj6Xl9rfCcd/+M4riScFtfMLBcYDSwEerr7NoDw3x51LBpL9wLfAqqqTUuE7AOBUuChcDP9ATPrTJxnd/ctwE+BTcA2oMzdXyLOc5+itqyN+tyq+E6yGqbF9bk+ZtYFeAK4y933xzpPQ5jZ5cBOd18S6yyNkAKcDfza3UcDB4mfzcNahfvDrgLygD5AZzP7YmxTNZtGfW5VfCeVAP2qPe4LbI1RlnqZWSpB6f3J3Z8MJ+8ws97h872BnbHKV4fzgCvNbAPwCHCRmf2RxMheApS4+8Lw8eMERRjv2S8G1rt7qbsfA54EJhD/uaurLWujPrcqvpMWA/lmlmdm7Qh2mM6LcaYamZkBDwKr3P3n1Z6aB3wp/P5LBPv+4oq7z3T3vu6eS/A7fs3dv0hiZN8ObDazIeGkKcBK4j/7JmCcmXUK/3amEByUiffc1dWWdR5wnZm1N7M8IB9YVO+rxXonZjx9AdOBNcDHwLdjnaeOnBMJVuc/AJaGX9OBTIKDBh+F/3aPddZ6fo4LOXlwIyGyA6OAovB3/xSQkQjZgR8Aq4HlwB+A9vGaG5hLsC/yGMEa3U11ZQW+HX5mi4FpDXkPXbImIpGjTV0RiRwVn4hEjopPRCJHxScikaPiE5HIUfFJJJnZhcdHhpHoUfGJSOSo+CSumdkXzWyRmS01s9+E4/gdMLOfmdl7ZvaqmWWH844ys3fN7AMz+8vxMdvMbLCZvWJmy8JlBoUv36Xa2Hp/Cq9qwMx+bGYrw9f5aYx+dGlBKj6JW2Z2FnAtcJ67jwIqgRuAzsB77n428AbwvXCR3wN3u/sI4MNq0/8E/NLdRxJco7otnD4auItg/MWBwHlm1h24Ghgavs5/tuTPKLGh4pN4NgUYAyw2s6Xh44EEw1k9Gs7zR2CimaUD3dz9jXD674DzzawrkOPufwFw9yPufiicZ5G7l7h7FcFlf7nAfuAI8ICZ/QNwfF5pQ1R8Es8M+J27jwq/hrj792uYr67rLmsatui4o9W+rwRS3L0COJdg5JvPAi+cXmRJBCo+iWevAv9oZj3gxH0XBhD83f5jOM8XgLfcvQzYa2aTwuk3Am94ME5hiZl9NnyN9mbWqbY3DMc4THf35wg2g0c1+08lMZcS6wAitXH3lWb2HeAlM0siGK3jVoIBQIea2RKgjGA/IATDFd0fFts6YEY4/UbgN2b27+FrfL6Ot+0KPG1mHQjWFr/ezD+WxAGNziIJx8wOuHuXWOeQxKVNXRGJHK3xiUjkaI1PRCJHxScikaPiE5HIUfGJSOSo+EQkcv4/XZ/BcZJI3XQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=50, verbose=1)\n",
    "\n",
    "from sklearn import metrics as mt\n",
    "yhat_proba = model.predict(X_test)\n",
    "yhat = np.round(yhat_proba)\n",
    "print(mt.confusion_matrix(y_test,yhat))\n",
    "print(mt.classification_report(y_test,yhat))\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "#plt.ylabel('Accuracy %')\n",
    "#plt.title('Training')\n",
    "#plt.subplot(2,2,2)\n",
    "#plt.plot(history.history['val_accuracy'])\n",
    "#plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "#plt.subplot(2,2,4)\n",
    "#plt.plot(history.history['val_loss'])\n",
    "#plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
